\section{Experiment}

\subsection{Data}
To experiment our algorithm we use the dataset 20Newsgroups \cite{Newsgroups20}.
The 20 Newsgroups data set is a collection of approximately 20,000 Newsgroups 
documents, partitioned evenly across 20 different newsgroups. We use also the 
RCV1 dataset \cite{Lewis:2004:RNB:1005332.1005345}. The RCV1 dataset is a 
collection of over 800,000 text documents. For RCV1 dataset, we use only a 
subset of 10,000 documents from RCV1 such that each document belongs to only 
one of the root classes in the class hierarchy. This was detailed in 
[\cite{Deap-K-Means}].\\
Each document are represented by a vector using term frequency-inverse document 
frequency (TFIDF) representation~\cite{doi:10.1108/eb026526}.
The term frequency-inverse document frequency is a method of weighting depicting 
the significance of each word of a document in relative to a corpus.
\begin{equation}
TF(t, X) = \frac{f_{t, X}}{max_{t' \in C}f_{t', X}} 
\end{equation}
\begin{equation}
IDF(t, C) = log(\frac{N}{|X \in C : t \in X|})
\end{equation}
\begin{equation}
TFIDF(t,X,C) = TF(t, X) . IDF(t, C)   
\end{equation}
For each dataset there is a preprocessing step. We remove stopword and keep only
the 2000 words with the top TFIDF scores. We use also a stemming step 
\cite{journals/mtcl/Lovins68} for dataset 20 Newsgroups. 
\subsection{Generate Constraint}
\subsubsection{Lexical Constraints}
To generate the set of keywords $KW$ we rank each word of each 
document of each class using TFIDF according to algorithm~\ref{algo:gen_kw}.
We add for each document of each class the tfidf of each word, in this manner
we find the most important word of each class. Furthermore, we substract 
the tdidf of other class, so that the keywords are the most discriminating.
\begin{algorithm}
  \SetKwInOut{Input}{input}
  \SetKwInOut{Output}{output}
  \Input{Corpus C, The number of keywords per classes $P$}
  \Output{KW}
  $KW \gets \{\}$\\
  \ForEach{Class $c_i \in C$}{
    $rank_i \gets [0 ... 0]$\\
    \ForEach{Document $X \in c_i$}{
      \ForEach{Word $w \in X$}{
        $rank_{i,w} \gets rank_{i,w} + TFIDF(w,X, C)$\\
      }
    }
  }
  \If{$Discriminating\_ Extraction$}{
    \ForEach{Class $c_i \in C$}{
      ${rank'}_i \gets rank_i - \sum\limits_{\forall c_j, cj \neq c_i}rank_j$\\
    }
    $rank \gets rank'$
  }
  \ForEach{Class $c_i \in C$}{
    $KW \gets KW \cup \{\{w_1, w_2 ... w_P\} : \not\exists (v_1, v_2) | v_1 \not\in 
    \{w_1, w_2 ... w_P\}, v_2 \in \{w_1, w_2 ... w_P\}, rank_{i,v_1} \ge rank_{i,v_2}\}$\\
  }
  \Return{KW}
  \caption{\label{algo:gen_kw}Extract Keywords}
\end{algorithm}
%\subsubsection{Background Knowledge}
%We generate pairwise constraints randomly accordinf to algorithm
%~\ref{algo:gen_pair}
%\begin{algorithm}[!h]
%  \SetKwInOut{Input}{input}
%  \SetKwInOut{Output}{output}
%  \Input{Corpus C, The set of labels L, The number of pair $N_p$}
%  \Output{Must-Link Pair ML, Cannot-Link Pair CL}
%  \For{p = 1 : $N_p$}{
%    \Repeat{$X_i \neq X_j \wedge L_i = L_j$}{
%      Choose randomly ($X_i, X_j$)\\
%    }
%    Insert ($X_i, X_j$) in ML\\
%  }
%  \For{p = 1 : $N_p$}{
%    \Repeat{$X_i \neq X_j \wedge L_i \neq L_j$}{
%      Choose randomly ($X_i, X_j$)\\
%    }
%    Insert ($X_i, X_j$) in ML\\
%  }
%  \Return{ML, CL}
%  \caption{\label{algo:gen_pair}Extract Pair}
%\end{algorithm}
\subsection{Evaluation}
\subsubsection{Baseline Algorithm}
We evaluate our algorithm with $K$-Means and Deep $K$-Means with pretraining 
see in section~\ref{seq:DeepClust}.
\subsubsection{Metric}
To evaluate our algorithm and compare results with reference algorithms we can
use the NMI Metric, Accuracy Metric \cite{NMI_ACC}, and Adjusted
Rand index\cite{ARI}. 
\begin{itemize}
\item NMI is an information-theoretic measure based on the mutual information of the ground-truth classes
and the obtained clusters, normalized using the entropy of each. The NMI Metric is defined as follows
$$NMI(S,C) = \frac{I(S,C)}{[H(S)+H(C)]/2}$$ 
with
$I(S,C) =\sum\limits_k \sum\limits_f\frac{|s_k \cap c_f|}{N}log\frac{N|s_k \cap c_f|}{|s_k| |c_f|}$
and
$H(S) = -\sum\limits_k\frac{|s_k|}{N}log\frac{N|s_k|}{|s_k|}$
\item The Accuracy is the proportion of true results among the total
  number of cases examined. The Accuracy metric is defined as follows :
$$
ACC(S,C) = \frac{1}{N}\sum\limits_k {max}_j|s_k \cap c_j|
$$
\item Let a be the number of pairs of document in C
  that are in the same cluster in the predicted partition and in the
  same cluster in the real partition, and b be the number of pairs of
  document in C that are in different clusters in predicted partition
  and in different cluster in real partition.
  The Adjusted Rand index is defined as follows :
  $$ARI = \frac{a+b}{\binom{N}{2}}$$
\end{itemize}
\subsection{Experimental Setup}
\subsubsection{Autoencoder Architecture}
We use the same architecture used in~\cite{Deap-K-Means}. The encoder is a fully-connected 
multilayer perceptron formed by 3 hidden layers (with dimensions 500, 500, 2000) 
and an embedding layer (with dimension K, the number of cluster). 
The decoder is a mirrored version of the encoder~\ref{fig:autoenc}.
The ReLu activation function is used on layers, except for the third
hidden layer of encoder and decoder part.
\\When we add the additional class, metrics are computed only with
documents that do not belong to the additional class.
\subsubsection{Hyperparameters}
We used Grid Search~\cite{SWANN1969S39} strategy for 
$\lambda_0$ and $\lambda_1$ optimization. We search on the range 
$[10^{-4},10^{-3},10^{-2},10^{-1}]$ for $\lambda_0$ and on the range
$[10^{-3},5.10^{-3},10^{-2},5.10^{-2},10^{-1}]$ for $\lambda_1$ with 10 runs.   
The results of Grid Search are reported 
in table~\ref{tab:res}. Hyperparameters $alpha_1$, $alpha_2$ and $\eta$ 
are set to 0, because we focused on the lexical constraints in the experiments. 
\begin{table}[!h]
\centering
%\resizebox{\hsize}{!}{
  \begin{tabular}{| l | l | l | l |}
    \hline
               & 20NEWS Without noise & 20NEWS With noise & RCV1 Without noise 
\\ \hline
    $\lambda$  & $10^{-3}$            & $10^{-2}$         & $10^{-4}$           
\\ \hline
    $\alpha_0$ & $5.10^{-2}$          & $5.10^{-3}$       & $10^{-2}$           
\\ \hline
  \end{tabular}
%}
  \caption{\label{tab2}Best results of Grid Search for the optimization of
hyperparameters for each dataset.}
\end{table}

\subsection{Results}
The purpose of the experiment is to rediscover the different classes of 
datasets with keywords.\\
To add noise to 20 newsgroups datasetw e divide the dataset into two corpus $C_1, C_2$. 
Each corpus contain ten classes. We generate keywords \ref{algo:gen_kw} 
from $C_1$. Then we concatenate document from corpus $C_1$ with document
from corpus $C_2$. The clustering processed on corpus $C_1$. For this experiment
we extract 3 keywords per class (see algorithm \ref{algo:gen_kw}).
\\Results are reported in table \ref{tab:res}.
\begin{table}[h]
\caption{\label{tab:res}Clustering applies to 
different learned latent space to measure the efficiency of lexical constraints
for $K$-Means algorithm. Performance is measured in terms of NMI, Adjusted Rand 
Index and clustering Accuracy, higher is better. Each cell contains the average
and the standard deviation computed over 10 runs. The best result for each 
metric/dataset is bold.}
\centering
%\resizebox{\hsize}{!}{
  \begin{tabular}{|l|l|l|l|}
    \hline
    & ACC          &ARI           & NMI           \\ \hline
    20NEWS without noise   &$36.1 \pm 2.2$&$13.3 \pm 1.7$&$40.9 \pm 1.6$ \\ \hline
    20NEWS with noise      &$33.1 \pm 2.7$&$8.7 \pm 1.3$ &$26.3 \pm 1.6$ \\ \hline
    RCV1 without noise     &$48.8 \pm 6.6$&$18.4 \pm 6.0$&$29.7 \pm 5.8$ \\ \hline
  \end{tabular}
%}
\subcaption*{K-Means}
%\resizebox{\hsize}{!}{
  \begin{tabular}{|l|l|l|l|}
    \hline
    & ACC          &ARI           & NMI           \\ \hline
    20NEWS without noise   &$53.1 \pm 2.3$&$35.0 \pm 1.4$&$49.3 \pm 1.0$ \\ \hline
    20NEWS with noise      &$\boldmath45.2 \pm 3.3$&$23.0 \pm 2.5$ &$30.0 \pm 2.0$ \\ \hline
    RCV1 without noise     &$51.3 \pm 3.5$&$17.5 \pm 5.8$&$24.5 \pm 5.1$ \\ \hline
  \end{tabular}
%}
\subcaption*{Simple pretrain + K-Means}
%\resizebox{\hsize}{!}{
  \begin{tabular}{|l|l|l|l|}
    \hline
    & ACC          &ARI           & NMI           \\ \hline
    20NEWS without noise   &$52.1 \pm 2.2$&$34.6 \pm 1.1$&$47.9 \pm 0.8$ \\ \hline
    20NEWS with noise      &$44.8 \pm 2.9$&$23.0 \pm 2.2$ &$29.3 \pm 1.7$ \\ \hline
    RCV1 without noise     &$62.0 \pm 5.3$&$27.8 \pm 5.2$&$33.0 \pm 6.4$ \\ \hline
  \end{tabular}
%}
\subcaption*{Lexical pretrain + K-Means}
%\resizebox{\hsize}{!}{
  \begin{tabular}{|l|l|l|l|}
    \hline
    & ACC          &ARI          & NMI          \\ \hline
    20NEWS without noise    & $54.9\pm 1.7$&$37.6\pm 1.1$&$51.6\pm 0.6$ \\ \hline
    20NEWS with noise       & $44.5\pm 2.4$&$23.6\pm 2.4$&$30.2\pm 2.0$ \\ \hline
    RCV1 without noise      &$54.4\pm 4.9$ &$23.9\pm 3.5$&$29.6\pm 3.6$ \\ \hline
  \end{tabular}
%}
\subcaption*{Deep K-Means}
%\resizebox{\hsize}{!}{
  \begin{tabular}{|l|l|l|l|}
    \hline
    & ACC                  &ARI                   & NMI                   \\ \hline
    20NEWS without noise   &$55.7\pm 2.3$  &$39.1\pm 1.1$    &$51.9\pm 0.7$ \\ \hline
    20NEWS with noise      &$44.3\pm 2.6$  &$23.5\pm 1.9$&$29.8\pm 1.7$ \\ \hline
    RCV1 without noise     &\boldmath$64.6\pm 5.7$&\boldmath$31.0\pm 5.0$&\boldmath$36.7 \pm 4.2$  \\ \hline
  \end{tabular}
%}
\subcaption*{Constrained Deep K-means, Lexical Pretrain, Unclustered keywords}
%\resizebox{\hsize}{!}{
  \begin{tabular}{|l|l|l|l|}
    \hline
    & ACC                  &ARI                   & NMI                   \\ \hline
    20NEWS without noise   &$57.6\pm 2.2$  &$39.8\pm 1.2$    &$52.6\pm 0.6$ \\ \hline
    20NEWS with noise      &$44.5\pm 2.5$  &$24.0\pm 2.3$&\boldmath$30.5\pm 2.$ \\ \hline
    RCV1 without noise     &$57.4\pm 6.4$&$29.1\pm 4.3$&$34.8 \pm 5.3$  \\ \hline
  \end{tabular}
%}
\subcaption*{Constrained Deep K-means,  Simple Pretrain, Unclustered keywords}
%\resizebox{\hsize}{!}{
  \begin{tabular}{|l|l|l|l|}
    \hline
    & ACC                  &ARI                   & NMI                   \\ \hline
    20NEWS without noise   &$55.7\pm 2.5$  &$39.4\pm 1.1$    &$52.1\pm 0.8$ \\ \hline
    20NEWS with noise      &$44.3\pm 1.8$  &\boldmath$24.4\pm 1$&$30.6\pm 0.8$ \\ \hline
    RCV1 without noise     &$53.3\pm 5.2$&$26.3\pm 5.2$&$32.8 \pm 4.2$  \\ \hline
  \end{tabular}
%}
\subcaption*{Constrained Deep K-means, Lexical Pretrain, Unclustered keywords with additionnal class}
%\resizebox{\hsize}{!}{
  \begin{tabular}{|l|l|l|l|}
    \hline
    & ACC                  &ARI                   & NMI                   \\ \hline
    20NEWS without noise   &\boldmath$58.8\pm 2$  &\boldmath$41.3\pm 1.4$    &\boldmath$53.5\pm 0.8$ \\ \hline
    20NEWS with noise      &$43.7\pm 1.6$  &$24.3\pm 1.3$&\boldmath$30.7\pm 1.2$ \\ \hline
    RCV1 without noise     &$52.2\pm 5.3$&$22.9\pm 4$&$29.4 \pm 3.7$  \\ \hline
  \end{tabular}
%}
\subcaption*{Constrained Deep K-means, Simple Pretrain, Unclustered keywords with additionnal class}
\end{table}

\subsection{Robustness}
We can also test the robustness of our algorithm. To test this, we
can vary the number of keywords by classes. In addition we compare
the results of each version of our two methods (simple/lexical pretrain, adding 
class) for each dataset.
We can see results  in 
figures \ref{fig:rcv1}, \ref{fig:20news}, \ref{fig:20news_noise}.
\begin{figure}[!h]
  \begin{subfigure}[b]{\textwidth}
    \centering
    \includegraphics[scale=0.82]{parts/res/dat_file/acc/RCV1_ACC.png}     
  \end{subfigure}
  \begin{subfigure}[b]{\textwidth}
    \centering
    \includegraphics[scale=0.82]{parts/res/dat_file/ari/RCV1_ARI.png}     
  \end{subfigure}
  \begin{subfigure}[b]{\textwidth}
    \centering
    \includegraphics[scale=0.82]{parts/res/dat_file/nmi/RCV1_NMI.png}     
  \end{subfigure}
  \caption{\label{fig:rcv1}Results for RCV1 dataset}
\end{figure}

\begin{figure}[!h]
  \begin{subfigure}[b]{\textwidth}
    \centering
    \includegraphics[scale=0.82]{parts/res/dat_file/acc/20NEWS_ACC.png}     
  \end{subfigure}
  \begin{subfigure}[b]{\textwidth}
    \centering
    \includegraphics[scale=0.82]{parts/res/dat_file/ari/20NEWS_ARI.png}     
  \end{subfigure}
  \begin{subfigure}[b]{\textwidth}
    \centering
    \includegraphics[scale=0.82]{parts/res/dat_file/nmi/20NEWS_NMI.png}     
  \end{subfigure}\caption{\label{fig:20news}Results for 20 newsgroups dataset}
\end{figure}

\begin{figure}[!h]
  \begin{subfigure}[b]{\textwidth}
    \centering
    \includegraphics[scale=0.82]{parts/res/dat_file/acc/20NEWS_noisy_ACC.png}     
  \end{subfigure}
  \begin{subfigure}[b]{\textwidth}
    \centering
    \includegraphics[scale=0.82]{parts/res/dat_file/ari/20NEWS_noisy_ARI.png}     
  \end{subfigure}
  \begin{subfigure}[b]{\textwidth}
    \centering
    \includegraphics[scale=0.82]{parts/res/dat_file/nmi/20NEWS_noisy_NMI.png}
  \end{subfigure}\caption{\label{fig:20news_noise}Results for 20 newsgroups dataset with noise}
\end{figure}

\subsection{User Test}
For user test, we extract keywords without taking into account class information. In other 
word, We add for each document the tfidf of each word. We can see the algorithm in 
\ref{algo:gen_kw_user}. This test allows to know the performance of our algorithm
in practical condition.
\begin{algorithm}
  \SetKwInOut{Input}{input}
  \SetKwInOut{Output}{output}
  \Input{Corpus C, The number of keywords $P$}
  \Output{KW}
  $KW \gets \{\}$\\
  \ForEach{Document $X \in c_i$}{
    \ForEach{Word $w \in X$}{
      $rank_{w} \gets rank_{w} + TFIDF(w,X,C)$\\
    }
  }
  \ForEach{Class $c_i \in C$}{
    $KW \gets KW \cup \{\{w_1, w_2 ... w_P\} : \not\exists (v_1, v_2) | v_1 \not\in 
    \{w_1, w_2 ... w_P\}, v_2 \in \{w_1, w_2 ... w_P\}, rank_{v_1} \ge rank_{v_2}\}$\\
  }
  \Return{KW}
  \caption{\label{algo:gen_kw_user}Extract Keywords II}
\end{algorithm}