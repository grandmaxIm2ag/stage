@ARTICLE{2015arXiv151106321H,
   author = {{Hsu}, Y.-C. and {Kira}, Z.},
    title = "{Neural network-based clustering using pairwise constraints}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1511.06321},
 primaryClass = "cs.LG",
 keywords = {Computer Science - Learning, Statistics - Machine Learning},
     year = 2015,
    month = nov,
   adsurl = {http://adsabs.harvard.edu/abs/2015arXiv151106321H},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{2016arXiv161004794Y,
   author = {{Yang}, B. and {Fu}, X. and {Sidiropoulos}, N.~D. and {Hong}, M.
	},
    title = "{Towards K-means-friendly Spaces: Simultaneous Deep Learning and Clustering}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1610.04794},
 primaryClass = "cs.LG",
 keywords = {Computer Science - Learning},
     year = 2016,
    month = oct,
   adsurl = {http://adsabs.harvard.edu/abs/2016arXiv161004794Y},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{doi:10.1108/eb026526,
author = {KAREN SPARCK JONES},
title = {A STATISTICAL INTERPRETATION OF TERM SPECIFICITY AND ITS APPLICATION IN RETRIEVAL},
journal = {Journal of Documentation},
volume = {28},
number = {1},
pages = {11-21},
year = {1972},
doi = {10.1108/eb026526},

URL = { 
        https://doi.org/10.1108/eb026526
    
},
eprint = { 
        https://doi.org/10.1108/eb026526
    
}
,
    abstract = { The exhaustivity of document descriptions and the specificity of index terms are usually regarded as independent. It is suggested that specificity should be interpreted statistically, as a function of term use rather than of term meaning. The effects on retrieval of variations in term specificity are examined, experiments with three test collections showing in particular that frequently‚Äêoccurring terms are required for good overall performance. It is argued that terms should be weighted according to collection frequency, so that matches on less frequent, more specific, terms are of greater value than matches on frequent terms. Results for the test collections show that considerable improvements in performance are obtained with this very simple procedure. }
}

@book{Goodfellow-et-al-2016,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}

@book{Deap-K-Means,
    title={Deep K-Means : An End-to-End, Annealing-based Approach for jointly Clustering with K-Means and Learning Representations},
    author={Maziar Moradi Fard and Thibaut Thonet and Eric Gaussier},
    publisher = {On submition}
}

@inproceedings{Wagstaff:2001:CKC:645530.655669,
 author = {Wagstaff, Kiri and Cardie, Claire and Rogers, Seth and Schr\"{o}dl, Stefan},
 title = {Constrained K-means Clustering with Background Knowledge},
 booktitle = {Proceedings of the Eighteenth International Conference on Machine Learning},
 series = {ICML '01},
 year = {2001},
 isbn = {1-55860-778-1},
 pages = {577--584},
 numpages = {8},
 url = {http://dl.acm.org/citation.cfm?id=645530.655669},
 acmid = {655669},
 publisher = {Morgan Kaufmann Publishers Inc.},
 address = {San Francisco, CA, USA},
}

@ARTICLE{2018arXiv180107648A,
   author = {{Aljalbout}, E. and {Golkov}, V. and {Siddiqui}, Y. and {Cremers}, D.
	},
    title = "{Clustering with Deep Learning: Taxonomy and New Methods}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1801.07648},
 primaryClass = "cs.LG",
 keywords = {Computer Science - Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning, 62H30, 62M45, 91C20, H.3.3, I.2.6, I.5, I.5.3, I.5.4},
     year = 2018,
    month = jan,
   adsurl = {http://adsabs.harvard.edu/abs/2018arXiv180107648A},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}
@ARTICLE{2015arXiv151106335X,
   author = {{Xie}, J. and {Girshick}, R. and {Farhadi}, A.},
    title = "{Unsupervised Deep Embedding for Clustering Analysis}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1511.06335},
 primaryClass = "cs.LG",
 keywords = {Computer Science - Learning, Computer Science - Computer Vision and Pattern Recognition},
     year = 2015,
    month = nov,
   adsurl = {http://adsabs.harvard.edu/abs/2015arXiv151106335X},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}
@ARTICLE{1056489,
author={S. Lloyd},
journal={IEEE Transactions on Information Theory},
title={Least squares quantization in PCM},
year={1982},
volume={28},
number={2},
pages={129-137},
keywords={Least-squares approximation;PCM communication;Quantization (signal);Signal quantization},
doi={10.1109/TIT.1982.1056489},
ISSN={0018-9448},
month={March},}
@misc{Newsgroups20,
added-at = {2012-05-12T16:39:37.000+0200},
author = {{empty}},
biburl = {https://www.bibsonomy.org/bibtex/2133313f1254d09b6ae89da442b62f3bc/lopusz_kdd},
editor = {{empty}},
interhash = {77445767e91f49215dc81ff8236ca9d5},
intrahash = {133313f1254d09b6ae89da442b62f3bc},
keywords = {dataset},
timestamp = {2012-05-12T18:24:34.000+0200},
title = { 20 Newsgroups Dataset},
url = {http://people.csail.mit.edu/jrennie/20Newsgroups/},
year = {{empty}}
}

@article{NMI_ACC,
title = "Locally consistent concept factorization for document clustering",
abstract = "Previous studies have demonstrated that document clustering performance can be improved significantly in lower dimensional linear subspaces. Recently, matrix factorization-based techniques, such as Nonnegative Matrix Factorization (NMF) and Concept Factorization (CF), have yielded impressive results. However, both of them effectively see only the global euclidean geometry, whereas the local manifold geometry is not fully considered. In this paper, we propose a new approach to extract the document concepts which are consistent with the manifold geometry such that each concept corresponds to a connected component. Central to our approach is a graph model which captures the local geometry of the document submanifold. Thus, we call it Locally Consistent Concept Factorization (LCCF). By using the graph Laplacian to smooth the document-to-concept mapping, LCCF can extract concepts with respect to the intrinsic manifold structure and thus documents associated with the same concept can be well clustered. The experimental results on TDT2 and Reuters-21578 have shown that the proposed approach provides a better representation and achieves better clustering results in terms of accuracy and mutual information.",
keywords = "clustering., concept factorization, graph Laplacian, manifold regularization, Nonnegative matrix factorization",
author = "Deng Cai and Xiaofei He and Jiawei Han",
year = "2011",
month = "3",
day = "15",
doi = "10.1109/TKDE.2010.165",
language = "English (US)",
volume = "23",
pages = "902--913",
journal = "IEEE Transactions on Knowledge and Data Engineering",
issn = "1041-4347",
publisher = "IEEE Computer Society",
number = "6",
}
 BibTeX | EndNote | ACM Ref

@article{ARI,
author = {Vinh, Nguyen Xuan and Epps, Julien and Bailey, James},
title = {Information Theoretic Measures for Clusterings Comparison: Variants, Properties, Normalization and Correction for Chance},
journal = {J. Mach. Learn. Res.},
issue_date = {3/1/2010},
volume = {11},
month = dec,
year = {2010},
issn = {1532-4435},
pages = {2837--2854},
numpages = {18},
url = {http://dl.acm.org/citation.cfm?id=1756006.1953024},
acmid = {1953024},
publisher = {JMLR.org},
}
             